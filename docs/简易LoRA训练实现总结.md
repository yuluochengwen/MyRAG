# ç®€æ˜“ LoRA è®­ç»ƒç³»ç»Ÿ - å®ç°æ€»ç»“

## ğŸ“‹ é¡¹ç›®æ¦‚è¿°

æ ¹æ®æ‚¨çš„éœ€æ±‚ï¼š"è‡ªå·±å†™ä¸€ä¸ªå¾®è°ƒä»£ç ï¼Œå¦å¼€ä¸€ä¸ªé¡µé¢ï¼Œåªä¼ æ•°æ®é›†å’Œé€‰æ‹©åŸºåº§æ¨¡å‹ï¼Œå‰©ä¸‹çš„è‡ªåŠ¨å¤„ç†"ï¼Œå·²å®Œæˆç‹¬ç«‹çš„ç®€åŒ–ç‰ˆ LoRA è®­ç»ƒç³»ç»Ÿã€‚

**æ ¸å¿ƒç‰¹ç‚¹ï¼š**
- âœ… ç‹¬ç«‹äº LLaMA-Factory
- âœ… åªéœ€ä¸Šä¼ æ•°æ®é›† + é€‰æ‹©æ¨¡å‹
- âœ… å‚æ•°è‡ªåŠ¨ä¼˜åŒ–ï¼ˆé’ˆå¯¹ RTX 3060 6GBï¼‰
- âœ… å®æ—¶è®­ç»ƒè¿›åº¦ç›‘æ§
- âœ… åå°è®­ç»ƒï¼Œä¸é˜»å¡ç•Œé¢

---

## ğŸ¯ æŠ€æœ¯é€‰å‹

| ç»„ä»¶ | æŠ€æœ¯æ ˆ | è¯´æ˜ |
|------|--------|------|
| è®­ç»ƒæ¡†æ¶ | Hugging Face PEFT | ä¸šç•Œæ ‡å‡†çš„ LoRA å®ç° |
| æ¨¡å‹åŠ è½½ | Transformers | å…¼å®¹æ‰€æœ‰ HuggingFace æ¨¡å‹ |
| é‡åŒ–æŠ€æœ¯ | BitsAndBytes | 4-bit QLoRA |
| æ•°æ®å¤„ç† | Datasets | çµæ´»çš„æ•°æ®é›†åŠ è½½ |
| åç«¯ API | FastAPI | å¼‚æ­¥é«˜æ€§èƒ½ |
| å‰ç«¯ UI | Tailwind CSS | ç°ä»£åŒ–å“åº”å¼ |

---

## ğŸ“‚ æ–‡ä»¶æ¸…å•

### åç«¯æ–‡ä»¶ (3 ä¸ª)

1. **Backend/app/services/simple_lora_trainer.py** (420 è¡Œ)
   - æ ¸å¿ƒè®­ç»ƒé€»è¾‘
   - è‡ªåŠ¨å‚æ•°é…ç½®
   - åå°ä»»åŠ¡ç®¡ç†
   - è¿›åº¦å®æ—¶æ›´æ–°

2. **Backend/app/api/simple_lora.py** (240 è¡Œ)
   - RESTful API æ¥å£
   - 7 ä¸ªç«¯ç‚¹ï¼ˆæ¨¡å‹åˆ—è¡¨ã€ä¸Šä¼ ã€è®­ç»ƒã€çŠ¶æ€æŸ¥è¯¢ç­‰ï¼‰
   - å®Œæ•´çš„é”™è¯¯å¤„ç†

3. **Backend/scripts/init_simple_lora_tables.sql** (24 è¡Œ)
   - æ•°æ®åº“è¡¨ç»“æ„
   - ä»»åŠ¡çŠ¶æ€è¿½è¸ª

### å‰ç«¯æ–‡ä»¶ (2 ä¸ª)

4. **Frontend/simple-lora-training.html** (200 è¡Œ)
   - ç‹¬ç«‹è®­ç»ƒé¡µé¢
   - æ‹–æ‹½ä¸Šä¼ æ•°æ®é›†
   - å®æ—¶è¿›åº¦æ˜¾ç¤º
   - ä»»åŠ¡åˆ—è¡¨ç®¡ç†

5. **Frontend/js/simple-lora-training.js** (380 è¡Œ)
   - æ–‡ä»¶ä¸Šä¼ é€»è¾‘
   - API è°ƒç”¨å°è£…
   - 5 ç§’è‡ªåŠ¨è½®è¯¢
   - çŠ¶æ€å®æ—¶åˆ·æ–°

### é…ç½®æ–‡ä»¶ (3 ä¸ª)

6. **Backend/main.py** (å·²ä¿®æ”¹)
   - æ–°å¢ simple_lora_router è·¯ç”±

7. **Backend/requirements.txt** (å·²æ›´æ–°)
   - æ–°å¢ï¼špeft, datasets, trl

8. **start-training.bat** (å¯åŠ¨è„šæœ¬)
   - ä¸€é”®å¯åŠ¨è®­ç»ƒç³»ç»Ÿ

### æ–‡æ¡£ä¸ç¤ºä¾‹ (3 ä¸ª)

9. **docs/ç®€æ˜“LoRAè®­ç»ƒåŠŸèƒ½è¯´æ˜.md**
   - å®Œæ•´åŠŸèƒ½æ–‡æ¡£
   - API æ¥å£è¯´æ˜
   - å¸¸è§é—®é¢˜è§£ç­”

10. **docs/ç®€æ˜“LoRAè®­ç»ƒå¿«é€Ÿå¼€å§‹.md**
    - 5 åˆ†é’Ÿå¿«é€Ÿä¸Šæ‰‹æŒ‡å—
    - åˆ†æ­¥éª¤æ“ä½œè¯´æ˜

11. **TrainingData/example_alpaca_dataset.json**
    - ç¤ºä¾‹æ•°æ®é›†ï¼ˆ10 ä¸ªæ ·æœ¬ï¼‰
    - å¯ç›´æ¥ç”¨äºæµ‹è¯•è®­ç»ƒ

**æ€»è®¡ï¼š11 ä¸ªæ–‡ä»¶**

---

## ğŸ”§ æ ¸å¿ƒåŠŸèƒ½

### 1. è‡ªåŠ¨åŒ–å‚æ•°é…ç½®

ç³»ç»Ÿæ ¹æ®ç¡¬ä»¶è‡ªåŠ¨è®¾ç½®æœ€ä¼˜å‚æ•°ï¼š

```python
{
    "lora_rank": 16,              # é€‚é…å™¨ç§©
    "lora_alpha": 32,             # ç¼©æ”¾ç³»æ•°
    "lora_dropout": 0.05,         # é˜²è¿‡æ‹Ÿåˆ
    "num_epochs": 3,              # è®­ç»ƒè½®æ¬¡
    "batch_size": 4,              # æ‰¹æ¬¡å¤§å°
    "gradient_accumulation_steps": 4,  # æ¢¯åº¦ç´¯ç§¯
    "learning_rate": 2e-4,        # å­¦ä¹ ç‡
    "use_4bit": True,             # 4-bit é‡åŒ–
    "max_seq_length": 512         # æœ€å¤§é•¿åº¦
}
```

**ç”¨æˆ·æ— éœ€å…³å¿ƒè¿™äº›å‚æ•°ï¼**

### 2. æ•°æ®é›†æ”¯æŒ

æ”¯æŒä¸¤ç§æ ‡å‡†æ ¼å¼ï¼Œè‡ªåŠ¨è§£æï¼š

**Alpaca æ ¼å¼ï¼š**
```json
{
    "instruction": "é—®é¢˜æè¿°",
    "input": "é¢å¤–è¾“å…¥ï¼ˆå¯é€‰ï¼‰",
    "output": "æœŸæœ›è¾“å‡º"
}
```

**ShareGPT æ ¼å¼ï¼š**
```json
{
    "conversations": [
        {"from": "human", "value": "ç”¨æˆ·æ¶ˆæ¯"},
        {"from": "gpt", "value": "AIå›å¤"}
    ]
}
```

### 3. è®­ç»ƒæµç¨‹

```
ä¸Šä¼ æ•°æ®é›† â†’ é€‰æ‹©åŸºåº§ â†’ è¾“å…¥åç§° â†’ ç‚¹å‡»å¼€å§‹
    â†“
ç³»ç»Ÿè‡ªåŠ¨ï¼š
  1. åŠ è½½æ¨¡å‹ï¼ˆ4-bit é‡åŒ–ï¼‰
  2. é…ç½® LoRA
  3. å‡†å¤‡æ•°æ®
  4. åå°è®­ç»ƒ
  5. å®æ—¶æ›´æ–°è¿›åº¦
  6. è‡ªåŠ¨ä¿å­˜ç»“æœ
    â†“
è®­ç»ƒå®Œæˆ â†’ æ‰«ææ¨¡å‹ â†’ éƒ¨ç½²åˆ° Ollama â†’ ç»‘å®šåŠ©æ‰‹
```

### 4. API æ¥å£

| æ–¹æ³• | è·¯å¾„ | åŠŸèƒ½ |
|------|------|------|
| GET | /api/simple-lora/models | è·å–åŸºåº§æ¨¡å‹åˆ—è¡¨ |
| POST | /api/simple-lora/upload-dataset | ä¸Šä¼ è®­ç»ƒæ•°æ®é›† |
| POST | /api/simple-lora/train | åˆ›å»ºå¹¶å¯åŠ¨è®­ç»ƒ |
| GET | /api/simple-lora/tasks/{id} | æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€ |
| GET | /api/simple-lora/tasks | è·å–æ‰€æœ‰ä»»åŠ¡ |
| GET | /api/simple-lora/datasets | è·å–æ•°æ®é›†åˆ—è¡¨ |

---

## ğŸ’¾ æ•°æ®åº“è®¾è®¡

```sql
CREATE TABLE simple_lora_tasks (
    id INT AUTO_INCREMENT PRIMARY KEY,
    task_name VARCHAR(255) NOT NULL,
    base_model VARCHAR(255) NOT NULL,
    dataset_file VARCHAR(512) NOT NULL,
    dataset_type VARCHAR(50) DEFAULT 'alpaca',
    output_path VARCHAR(512) NOT NULL,
    training_params JSON,
    status ENUM('pending', 'running', 'completed', 'failed'),
    progress DECIMAL(5,2) DEFAULT 0.00,
    current_epoch INT DEFAULT 0,
    message TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    started_at TIMESTAMP NULL,
    completed_at TIMESTAMP NULL
);
```

**å­—æ®µè¯´æ˜ï¼š**
- `status`: ä»»åŠ¡çŠ¶æ€ï¼ˆç­‰å¾…/è¿è¡Œ/å®Œæˆ/å¤±è´¥ï¼‰
- `progress`: è®­ç»ƒè¿›åº¦ï¼ˆ0-100%ï¼‰
- `current_epoch`: å½“å‰è®­ç»ƒè½®æ¬¡
- `message`: çŠ¶æ€æ¶ˆæ¯ï¼ˆç”¨äºæ˜¾ç¤ºå½“å‰æ­¥éª¤ï¼‰

---

## ğŸ¨ å‰ç«¯ç•Œé¢

### å¸ƒå±€ç»“æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           å¯¼èˆªæ ï¼ˆè¿”å›ä¸»é¡µï¼‰                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   è®­ç»ƒé…ç½®ï¼ˆå·¦ä¾§ï¼‰     â”‚   ä»»åŠ¡åˆ—è¡¨ï¼ˆå³ä¾§ï¼‰    â”‚
â”‚                      â”‚                      â”‚
â”‚  æ­¥éª¤1: ä¸Šä¼ æ•°æ®é›†    â”‚   è¿è¡Œä¸­çš„ä»»åŠ¡        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚æ‹–æ‹½ä¸Šä¼ åŒºåŸŸ  â”‚   â”‚   â”‚ ä»»åŠ¡1 (65%)  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                      â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  æ­¥éª¤2: é€‰æ‹©åŸºåº§      â”‚   â”‚ ä»»åŠ¡2 å·²å®Œæˆ  â”‚  â”‚
â”‚  [ä¸‹æ‹‰åˆ—è¡¨]          â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                      â”‚                      â”‚
â”‚  æ­¥éª¤3: ä»»åŠ¡åç§°      â”‚   å†å²ä»»åŠ¡...        â”‚
â”‚  [è¾“å…¥æ¡†]            â”‚                      â”‚
â”‚                      â”‚                      â”‚
â”‚  è‡ªåŠ¨å‚æ•°è¯´æ˜         â”‚                      â”‚
â”‚  [å‚æ•°é¢æ¿]          â”‚                      â”‚
â”‚                      â”‚                      â”‚
â”‚  [å¼€å§‹è®­ç»ƒæŒ‰é’®]       â”‚                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### äº¤äº’ç‰¹æ€§

- âœ… æ‹–æ‹½ä¸Šä¼ ï¼ˆæ”¯æŒç‚¹å‡»é€‰æ‹©ï¼‰
- âœ… å®æ—¶è¿›åº¦æ¡ï¼ˆåŠ¨ç”»æ•ˆæœï¼‰
- âœ… è‡ªåŠ¨è½®è¯¢ï¼ˆ5 ç§’åˆ·æ–°ï¼‰
- âœ… çŠ¶æ€å¾½ç« ï¼ˆé¢œè‰²åŒºåˆ†ï¼‰
- âœ… Toast æç¤ºï¼ˆæˆåŠŸ/å¤±è´¥ï¼‰
- âœ… å“åº”å¼å¸ƒå±€ï¼ˆç§»åŠ¨ç«¯å‹å¥½ï¼‰

---

## ğŸš€ ä½¿ç”¨æµç¨‹

### æ­¥éª¤ 1: ç¯å¢ƒå‡†å¤‡ï¼ˆä¸€æ¬¡æ€§ï¼‰

```powershell
# å®‰è£…ä¾èµ–
pip install peft>=0.11.0 datasets>=2.18.0 trl>=0.8.0

# åˆå§‹åŒ–æ•°æ®åº“
mysql -u root -p rag_system < Backend/scripts/init_simple_lora_tables.sql
```

### æ­¥éª¤ 2: å¯åŠ¨æœåŠ¡

```powershell
# æ–¹æ³• 1: ä½¿ç”¨è„šæœ¬
.\start-training.bat

# æ–¹æ³• 2: æ‰‹åŠ¨å¯åŠ¨
cd Backend
python main.py
```

### æ­¥éª¤ 3: å¼€å§‹è®­ç»ƒ

1. è®¿é—®ï¼š`http://localhost:8000/static/simple-lora-training.html`
2. ä¸Šä¼ æ•°æ®é›†ï¼ˆJSON æ–‡ä»¶ï¼‰
3. é€‰æ‹©åŸºåº§æ¨¡å‹
4. è¾“å…¥ä»»åŠ¡åç§°
5. ç‚¹å‡»"å¼€å§‹è®­ç»ƒ"

### æ­¥éª¤ 4: ç›‘æ§è¿›åº¦

- å³ä¾§ä»»åŠ¡åˆ—è¡¨å®æ—¶æ˜¾ç¤º
- è¿›åº¦æ¡åŠ¨æ€æ›´æ–°
- çŠ¶æ€è‡ªåŠ¨åˆ‡æ¢

### æ­¥éª¤ 5: ä½¿ç”¨æ¨¡å‹

- è®­ç»ƒå®Œæˆåè‡ªåŠ¨ä¿å­˜åˆ° `Models/LoRA/`
- åœ¨æ¨¡å‹ç®¡ç†é¡µé¢æ‰«ææ–°æ¨¡å‹
- éƒ¨ç½²åˆ° Ollama
- åœ¨æ™ºèƒ½åŠ©æ‰‹ä¸­ç»‘å®š

---

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–

### æ˜¾å­˜ä¼˜åŒ–

- âœ… 4-bit é‡åŒ–ï¼ˆèŠ‚çœ 75% æ˜¾å­˜ï¼‰
- âœ… Gradient Checkpointingï¼ˆèŠ‚çœ 30% æ˜¾å­˜ï¼‰
- âœ… å°æ‰¹æ¬¡ + æ¢¯åº¦ç´¯ç§¯ï¼ˆæœ‰æ•ˆ batch=16ï¼‰

### è®­ç»ƒé€Ÿåº¦

- âœ… FP16 æ··åˆç²¾åº¦
- âœ… Flash Attentionï¼ˆå¦‚æœæ”¯æŒï¼‰
- âœ… ä¼˜åŒ–çš„ AdamW ä¼˜åŒ–å™¨

### é€‚é…ç¡¬ä»¶

| æ˜¾å¡ | æ˜¾å­˜ | æ”¯æŒæƒ…å†µ | å»ºè®® batch_size |
|------|------|---------|----------------|
| RTX 3060 | 6GB | âœ… å½“å‰é…ç½® | 4 |
| RTX 3070 | 8GB | âœ… å¯å¢å¤§ | 8 |
| RTX 4060 | 8GB | âœ… å¯å¢å¤§ | 8 |
| RTX 4070 | 12GB | âœ… å¯å¢å¤§ | 16 |

---

## âœ… éªŒè¯æ¸…å•

- [x] åç«¯æœåŠ¡æ­£å¸¸å¯åŠ¨
- [x] æ•°æ®åº“è¡¨åˆ›å»ºæˆåŠŸ
- [x] API æ¥å£æ— è¯­æ³•é”™è¯¯
- [x] å‰ç«¯é¡µé¢æ­£å¸¸åŠ è½½
- [x] æ–‡ä»¶ä¸Šä¼ åŠŸèƒ½æ­£å¸¸
- [x] è®­ç»ƒä»»åŠ¡å¯åˆ›å»º
- [x] è¿›åº¦å®æ—¶æ›´æ–°
- [x] æ¨¡å‹è‡ªåŠ¨ä¿å­˜

---

## ğŸ¯ åç»­å»ºè®®

### åŠŸèƒ½å¢å¼º

1. **é«˜çº§å‚æ•°é…ç½®**ï¼ˆå¯é€‰ï¼‰
   - å…è®¸ç”¨æˆ·è‡ªå®šä¹‰ rankã€alpha ç­‰å‚æ•°
   - æ·»åŠ "é«˜çº§æ¨¡å¼"å¼€å…³

2. **è®­ç»ƒç›‘æ§å¢å¼º**
   - æ˜¾ç¤ºè®­ç»ƒ loss æ›²çº¿
   - æ˜¾ç¤ºæ˜¾å­˜ä½¿ç”¨æƒ…å†µ
   - æ˜¾ç¤ºé¢„è®¡å‰©ä½™æ—¶é—´

3. **æ¨¡å‹è¯„ä¼°**
   - è®­ç»ƒå®Œæˆåè‡ªåŠ¨éªŒè¯
   - ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š

4. **æ•°æ®é›†ç®¡ç†**
   - åœ¨çº¿ç¼–è¾‘æ•°æ®é›†
   - æ•°æ®é›†é¢„è§ˆå’Œç»Ÿè®¡

### æ€§èƒ½ä¼˜åŒ–

1. **å¤š GPU æ”¯æŒ**
   - ä½¿ç”¨ DeepSpeed æˆ– FSDP
   - è‡ªåŠ¨æ£€æµ‹å¯ç”¨ GPU

2. **æ–­ç‚¹ç»­è®­**
   - æ”¯æŒä¸­é€”åœæ­¢å’Œæ¢å¤
   - ä¿å­˜ checkpoint

3. **åˆ†å¸ƒå¼è®­ç»ƒ**
   - æ”¯æŒå¤šæœºè®­ç»ƒ
   - ä½¿ç”¨ Ray æˆ– Horovod

---

## ğŸ“ æ€»ç»“

### å·²å®ç°

âœ… **ç‹¬ç«‹è®­ç»ƒç³»ç»Ÿ**ï¼šä¸ä¾èµ– LLaMA-Factoryï¼Œè‡ªä¸»å¯æ§  
âœ… **æç®€æ“ä½œ**ï¼šåªéœ€ä¸Šä¼ æ•°æ®é›† + é€‰æ‹©æ¨¡å‹  
âœ… **è‡ªåŠ¨åŒ–**ï¼šå‚æ•°é…ç½®ã€è®­ç»ƒç›‘æ§ã€ç»“æœä¿å­˜å…¨è‡ªåŠ¨  
âœ… **å®æ—¶ç›‘æ§**ï¼šè¿›åº¦æ¡ã€çŠ¶æ€æ›´æ–°ã€ä»»åŠ¡åˆ—è¡¨  
âœ… **å®Œæ•´æ–‡æ¡£**ï¼šå¿«é€Ÿå¼€å§‹ã€åŠŸèƒ½è¯´æ˜ã€API æ¥å£  
âœ… **ç¤ºä¾‹æ•°æ®**ï¼šæä¾›æµ‹è¯•æ•°æ®é›†ï¼Œå¼€ç®±å³ç”¨  

### ä¼˜åŠ¿

- ğŸš€ **ç®€å•**ï¼š3 æ­¥å®Œæˆè®­ç»ƒé…ç½®
- âš¡ **å¿«é€Ÿ**ï¼šå‚æ•°å·²ä¼˜åŒ–ï¼Œæ— éœ€è°ƒæ•´
- ğŸ’ª **ç¨³å®š**ï¼šæˆç†Ÿæ¡†æ¶ï¼Œç»è¿‡éªŒè¯
- ğŸ¨ **ç¾è§‚**ï¼šç°ä»£åŒ– UIï¼Œäº¤äº’å‹å¥½
- ğŸ“š **å®Œå–„**ï¼šæ–‡æ¡£é½å…¨ï¼Œæ˜“äºç»´æŠ¤

### é€‚ç”¨åœºæ™¯

- âœ… å¿«é€ŸéªŒè¯æƒ³æ³•
- âœ… å°è§„æ¨¡æ•°æ®é›†å¾®è°ƒ
- âœ… ç‰¹å®šé¢†åŸŸé€‚é…
- âœ… å¤šåŠ©æ‰‹åœºæ™¯ï¼ˆä¸åŒ LoRAï¼‰

---

**ç°åœ¨æ‚¨å¯ä»¥ä¸“æ³¨äºæ•°æ®å‡†å¤‡å’Œåº”ç”¨åœºæ™¯ï¼Œè®©æŠ€æœ¯ç»†èŠ‚è‡ªåŠ¨åŒ–ï¼** ğŸ‰
