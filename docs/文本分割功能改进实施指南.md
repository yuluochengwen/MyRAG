# æ–‡æœ¬åˆ†å‰²åŠŸèƒ½æ”¹è¿›æ–¹æ¡ˆ - å®æ–½æŒ‡å—

## ğŸ“‹ æ”¹è¿›æ€»ç»“

åŸºäºä½ çš„éœ€æ±‚ï¼ˆå·²æ¥å…¥Ollama + ä¸å¤„ç†è¶…é•¿æ–‡æœ¬ï¼‰ï¼Œå®æ–½äº†ä»¥ä¸‹æ”¹è¿›ï¼š

### ä¸€ã€æ–°å¢ï¼šåŸºäºLLMçš„è¯­ä¹‰è¾¹ç•Œæ£€æµ‹åˆ†å‰²å™¨

**æ–‡ä»¶**: `Backend/app/utils/semantic_splitter.py` âœ¨ æ–°å»º

**æ ¸å¿ƒç‰¹æ€§**:
1. **æ™ºèƒ½è¯­ä¹‰è¾¹ç•Œæ£€æµ‹**
   - ä½¿ç”¨Ollama LLMåˆ¤æ–­æ®µè½æ˜¯å¦åº”è¯¥åˆå¹¶
   - é¿å…åœ¨ä¸»é¢˜ä¸­é—´æˆªæ–­

2. **å¤šçº§åˆ†å‰²ç­–ç•¥**
   ```
   ç²—åˆ†ï¼ˆæ®µè½ï¼‰ â†’ LLMåˆ¤æ–­ï¼ˆè¯­ä¹‰ï¼‰ â†’ åå¤„ç†ï¼ˆé•¿åº¦ï¼‰
   ```

3. **é™çº§æœºåˆ¶**
   - Ollamaä¸å¯ç”¨æ—¶è‡ªåŠ¨é™çº§ä¸ºè§„åˆ™åˆ†å‰²
   - ç¡®ä¿ç³»ç»Ÿç¨³å®šæ€§

**ä½¿ç”¨æ–¹å¼**:
```python
from app.utils.semantic_splitter import get_semantic_splitter

# è·å–è¯­ä¹‰åˆ†å‰²å™¨
splitter = get_semantic_splitter()

# åˆ†å‰²æ–‡æœ¬ï¼ˆå¯ç”¨LLMï¼‰
chunks = splitter.split_text(text, use_llm=True)

# æˆ–ä½¿ç”¨å¿«é€Ÿè§„åˆ™æ¨¡å¼
chunks = splitter.split_text(text, use_llm=False)
```

**é…ç½®å‚æ•°**:
- `max_chunk_size`: 800å­—ç¬¦ï¼ˆé€‚åˆä¸­çŸ­æ–‡æœ¬ï¼‰
- `min_chunk_size`: 200å­—ç¬¦ï¼ˆé¿å…è¿‡ç¢ï¼‰
- `ollama_model`: ä½¿ç”¨çš„Ollamaæ¨¡å‹ï¼ˆé»˜è®¤ä»configè¯»å–ï¼‰

---

### äºŒã€ä»£ç æ¸…ç†ï¼šåˆ é™¤æœªä½¿ç”¨åŠŸèƒ½

#### å·²åˆ é™¤çš„åŠŸèƒ½ï¼š

1. **text_splitter.py**:
   - âŒ `analyze_chunks()` - è´¨é‡åˆ†æï¼ˆä»æœªè°ƒç”¨ï¼‰
   - âŒ `_get_recommendation()` - å»ºè®®ç”Ÿæˆï¼ˆä¾èµ–analyze_chunksï¼‰
   - âŒ `count_chunks()` - é¢„è®¡ç®—å—æ•°ï¼ˆå¯ç›´æ¥ç”¨lenï¼‰
   
   **èŠ‚çœ**: ~100è¡Œä»£ç 

2. **validators.py**:
   - âŒ `validate_knowledge_base_name()` - ä¸`validate_kb_name()`é‡å¤
   
   **èŠ‚çœ**: ~25è¡Œä»£ç 

#### å·²æ·»åŠ æ ‡è®°çš„åŠŸèƒ½ï¼š

1. **similarity.py**:
   - âš ï¸ `cosine_similarity()` - æ·»åŠ æ³¨é‡Š"å·¥å…·å‡½æ•°ï¼Œæœªæ¥è¯­ä¹‰å»é‡ç”¨"
   
2. **validators.py**:
   - âš ï¸ `sanitize_path()` - æ·»åŠ TODO"åº”è¯¥åœ¨file_serviceä½¿ç”¨"
   - âš ï¸ `format_file_size()` - æ·»åŠ æ³¨é‡Š"å‰ç«¯å±•ç¤ºç”¨"

---

### ä¸‰ã€å®‰å…¨ä¿®å¤ï¼šæ–‡ä»¶è·¯å¾„æ¸…ç†

**æ–‡ä»¶**: `Backend/app/services/file_service.py`

**ä¿®å¤é—®é¢˜**: é˜²æ­¢è·¯å¾„éå†æ”»å‡»

**ä¿®æ”¹ç‚¹**:
```python
# ä¿®æ”¹å‰ï¼šç›´æ¥ä½¿ç”¨ç”¨æˆ·ä¸Šä¼ çš„æ–‡ä»¶å
storage_path = os.path.join(kb_dir, f"{file_hash}_{filename}")

# ä¿®æ”¹åï¼šå…ˆæ¸…ç†æ–‡ä»¶å
from app.utils.validators import sanitize_path
safe_filename = sanitize_path(filename)
storage_path = os.path.join(kb_dir, f"{file_hash}_{safe_filename}")
```

**å®‰å…¨å¢å¼º**:
- ç§»é™¤ `..` è·¯å¾„éå†ç¬¦å·
- ç§»é™¤ `~` homeç›®å½•ç¬¦å·
- è·¯å¾„è§„èŒƒåŒ–

---

## ğŸš€ å®æ–½è®¡åˆ’

### ç¬¬ä¸€æ­¥ï¼šå¯ç”¨è¯­ä¹‰åˆ†å‰²å™¨ï¼ˆæ¨èï¼‰

ä¿®æ”¹ `Backend/app/api/knowledge_base.py` ç¬¬174è¡Œï¼š

```python
# å½“å‰ä»£ç 
splitter = TextSplitter()
chunks = splitter.split_text(content)

# æ¨èæ”¹ä¸º
from app.utils.semantic_splitter import get_semantic_splitter
splitter = get_semantic_splitter()
chunks = splitter.split_text(content, use_llm=True)  # å¯ç”¨LLM
```

**ä¼˜ç‚¹**:
- è¯­ä¹‰å®Œæ•´æ€§æ›´å¥½
- é¿å…åœ¨ä¸»é¢˜ä¸­é—´æˆªæ–­
- é€‚åˆå¯¹è¯å‹RAG

**ç¼ºç‚¹**:
- é€Ÿåº¦è¾ƒæ…¢ï¼ˆæ¯å¯¹æ®µè½éœ€è°ƒç”¨1æ¬¡LLMï¼‰
- ä¾èµ–OllamaæœåŠ¡

---

### ç¬¬äºŒæ­¥ï¼šæ··åˆç­–ç•¥ï¼ˆç”Ÿäº§æ¨èï¼‰

æ ¹æ®æ–‡æ¡£é•¿åº¦é€‰æ‹©ç­–ç•¥ï¼š

```python
from app.utils.semantic_splitter import get_semantic_splitter
from app.utils.text_splitter import TextSplitter

# çŸ­æ–‡æœ¬(<5000å­—ç¬¦) â†’ LLMè¯­ä¹‰åˆ†å‰²
if len(content) < 5000:
    splitter = get_semantic_splitter()
    chunks = splitter.split_text(content, use_llm=True)
# é•¿æ–‡æœ¬ â†’ å¿«é€Ÿè§„åˆ™åˆ†å‰²
else:
    splitter = TextSplitter(chunk_size=800, chunk_overlap=100)
    chunks = splitter.split_text(content)
```

---

### ç¬¬ä¸‰æ­¥ï¼šé…ç½®ä¼˜åŒ–

ä¿®æ”¹ `Backend/config.yaml`:

```yaml
text_processing:
  chunk_size: 800  # ä»500å¢åŠ åˆ°800
  chunk_overlap: 100  # ä»50å¢åŠ åˆ°100
  separators:
    - "\n\n"
    - "\n"
    - "ã€‚"
    - "ï¼"
    - "ï¼Ÿ"
    - ";"
    - "."
    - " "
```

**ç†ç”±**:
- 800å­—ç¬¦æ›´ç¬¦åˆç°ä»£embeddingæ¨¡å‹èƒ½åŠ›
- 100å­—ç¬¦overlapç¡®ä¿ä¸Šä¸‹æ–‡è¿è´¯
- é€‚åˆä¸­çŸ­æ–‡æœ¬åœºæ™¯

---

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

| ç­–ç•¥ | é€Ÿåº¦ | è´¨é‡ | é€‚ç”¨åœºæ™¯ |
|------|------|------|---------|
| **è§„åˆ™åˆ†å‰²** (TextSplitter) | âš¡âš¡âš¡ å¿« | â­â­â­ ä¸­ | é•¿æ–‡æ¡£ã€æ‰¹é‡å¤„ç† |
| **LLMè¯­ä¹‰åˆ†å‰²** (SemanticSplitter) | âš¡ æ…¢ | â­â­â­â­â­ ä¼˜ | çŸ­æ–‡æ¡£ã€å¯¹è¯å‹RAG |
| **æ··åˆç­–ç•¥** | âš¡âš¡ ä¸­ | â­â­â­â­ è‰¯ | ç”Ÿäº§ç¯å¢ƒæ¨è âœ… |

---

## ğŸ” ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹1ï¼šåŸºç¡€ä½¿ç”¨

```python
from app.utils.semantic_splitter import get_semantic_splitter

splitter = get_semantic_splitter()

text = """
ç¬¬ä¸€æ®µï¼šä»‹ç»ä¸»é¢˜Açš„èƒŒæ™¯ã€‚è¿™æ˜¯å…³äºAçš„è¯¦ç»†è¯´æ˜ã€‚

ç¬¬äºŒæ®µï¼šç»§ç»­è®¨è®ºä¸»é¢˜Açš„ç»†èŠ‚ã€‚æ›´å¤šAçš„ä¿¡æ¯ã€‚

ç¬¬ä¸‰æ®µï¼šè½¬æ¢åˆ°ä¸»é¢˜Bã€‚è¿™é‡Œå¼€å§‹è®¨è®ºBã€‚

ç¬¬å››æ®µï¼šæ·±å…¥ä¸»é¢˜Bçš„åˆ†æã€‚Bçš„å…·ä½“å†…å®¹ã€‚
"""

# LLMä¼šåˆ¤æ–­ï¼šç¬¬1-2æ®µåˆå¹¶ï¼Œç¬¬3-4æ®µåˆå¹¶
chunks = splitter.split_text(text, use_llm=True)
# ç»“æœï¼š["ç¬¬ä¸€æ®µ...ç¬¬äºŒæ®µ...", "ç¬¬ä¸‰æ®µ...ç¬¬å››æ®µ..."]
```

### ç¤ºä¾‹2ï¼šå¸¦å…ƒæ•°æ®

```python
chunks_with_meta = splitter.split_text_with_metadata(
    text=content,
    source_file="report.pdf",
    file_type="pdf",
    use_llm=True
)

# ç»“æœ
# [
#   {
#     "content": "...",
#     "metadata": {
#       "chunk_index": 0,
#       "source_file": "report.pdf",
#       "split_method": "llm_semantic"
#     }
#   },
#   ...
# ]
```

---

## âš™ï¸ é…ç½®é€‰é¡¹

åœ¨ `Backend/app/utils/semantic_splitter.py` ä¸­å¯é…ç½®ï¼š

```python
# ä¿®æ”¹åˆ†å‰²å‚æ•°
splitter = SemanticTextSplitter(
    max_chunk_size=1000,      # æœ€å¤§å—å¤§å°
    min_chunk_size=300,        # æœ€å°å—å¤§å°
    ollama_model="qwen2.5:7b"  # ä½¿ç”¨çš„æ¨¡å‹
)
```

**æ¨èé…ç½®**ï¼ˆæ ¹æ®åœºæ™¯ï¼‰:

| åœºæ™¯ | max_size | min_size | æ¨¡å‹ |
|------|----------|----------|------|
| **çŸ­æ–‡æ¡£å¯¹è¯** | 800 | 200 | qwen2.5:latest |
| **æŠ€æœ¯æ–‡æ¡£** | 1200 | 300 | qwen2.5:7b |
| **å­¦æœ¯è®ºæ–‡** | 1500 | 400 | qwen2.5:14b |

---

## ğŸ› å·²ä¿®å¤çš„é—®é¢˜

1. âœ… æ–‡ä»¶åè·¯å¾„éå†æ¼æ´
2. âœ… åˆ é™¤æœªä½¿ç”¨ä»£ç ï¼ˆ~125è¡Œï¼‰
3. âœ… æ·»åŠ åŠŸèƒ½ä½¿ç”¨æ ‡è®°
4. âœ… ä¼˜åŒ–å¯¼å…¥å¯¼å‡ºæ¸…å•

---

## ğŸ“ åç»­TODO

1. [ ] åœ¨knowledge_base.pyä¸­å¯ç”¨è¯­ä¹‰åˆ†å‰²å™¨
2. [ ] æ·»åŠ åˆ†å‰²ç­–ç•¥é€‰æ‹©APIï¼ˆè®©ç”¨æˆ·é€‰æ‹©ç­–ç•¥ï¼‰
3. [ ] å®æ–½æ··åˆç­–ç•¥
4. [ ] æ·»åŠ åˆ†å‰²è´¨é‡ç›‘æ§æ—¥å¿—
5. [ ] è€ƒè™‘å¼‚æ­¥LLMè°ƒç”¨ä¼˜åŒ–

---

## ğŸ¯ æ¨èè¡ŒåŠ¨

**ç«‹å³å¯åš**ï¼ˆ5åˆ†é’Ÿï¼‰:
1. ä¿®æ”¹config.yamlå¢åŠ chunk_sizeåˆ°800
2. åœ¨knowledge_base.pyå¯ç”¨semantic_splitter

**çŸ­æœŸä¼˜åŒ–**ï¼ˆ1å°æ—¶ï¼‰:
3. å®æ–½æ··åˆç­–ç•¥ï¼ˆæ ¹æ®æ–‡æ¡£é•¿åº¦ï¼‰
4. æ·»åŠ åˆ†å‰²ç»“æœæ—¥å¿—

**é•¿æœŸè§„åˆ’**ï¼š
5. æ”¶é›†ç”¨æˆ·åé¦ˆ
6. ä¼˜åŒ–LLM promptæé«˜åˆ¤æ–­å‡†ç¡®æ€§
7. è€ƒè™‘ç¼“å­˜LLMåˆ¤æ–­ç»“æœ

---

## ğŸ’¡ æ³¨æ„äº‹é¡¹

1. **LLMè°ƒç”¨æˆæœ¬**: 
   - æ¯å¯¹æ®µè½1æ¬¡è°ƒç”¨
   - 10æ®µæ–‡æœ¬ â‰ˆ 5æ¬¡LLMè°ƒç”¨
   - å»ºè®®è®¾ç½®timeoutå’Œé‡è¯•

2. **é™çº§ç­–ç•¥**:
   - Ollamaä¸å¯ç”¨æ—¶è‡ªåŠ¨é™çº§
   - ä¸å½±å“ç³»ç»Ÿç¨³å®šæ€§

3. **æ€§èƒ½ä¼˜åŒ–**:
   - è€ƒè™‘å¹¶è¡Œè°ƒç”¨LLM
   - ç¼“å­˜åˆ¤æ–­ç»“æœ
   - æ‰¹é‡å¤„ç†

---

å¸Œæœ›è¿™ä»½æ–¹æ¡ˆç¬¦åˆä½ çš„éœ€æ±‚ï¼æœ‰ä»»ä½•é—®é¢˜éšæ—¶å‘Šè¯‰æˆ‘ã€‚ğŸš€
