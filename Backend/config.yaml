# 应用配置
app:
  name: "MyRAG"
  version: "1.0.0"
  debug: true
  host: "0.0.0.0"
  port: 8000
  cors_origins:
    - "http://localhost"
    - "http://localhost:3000"
    - "http://127.0.0.1"

# 文件配置
file:
  max_size_mb: 100  # 单文件最大100MB
  total_max_size_mb: 500  # 总大小最大500MB
  allowed_extensions:
    - .txt
    - .md
    - .pdf
    - .docx
    - .doc
    - .html
    - .json
  upload_dir: "KnowledgeBase"  # 相对于项目根目录MyRAG/

# 文本处理配置
text_processing:
  chunk_size: 800  # 增加块大小以适应更多上下文
  chunk_overlap: 100  # 增加重叠以保持连贯性
  separators:
    - "\n\n"
    - "\n"
    - "。"
    - "！"
    - "？"
    - ";"
    - ";"
    - "."
    - " "
  
  # 语义分割配置（基于LLM）
  semantic_split:
    enabled: true  # 启用语义分割
    max_chunk_size: 800  # 语义块最大大小
    min_chunk_size: 200  # 语义块最小大小
    ollama_model: "deepseek-v3.1:671b-cloud"  # 用于语义判断的Ollama模型
    use_for_short_text: true  # 是否对短文本使用LLM分割
    short_text_threshold: 5000  # 短文本阈值（字符数）

# 向量数据库配置
vector_db:
  type: "chroma"
  persist_directory: "VectorDB"  # 相对于项目根目录MyRAG/
  collection_name_prefix: "kb_"

# 嵌入模型配置
embedding:
  provider: "transformers"  # 默认嵌入提供方: transformers, ollama
  default_model: "BERT-Base"
  model_dir: "Models/Embedding"  # 相对于项目根目录MyRAG/
  batch_size: 32
  max_length: 512
  
  # Ollama配置
  ollama:
    base_url: "http://localhost:11434"
    timeout: 30
    default_model: "nomic-embed-text"

# 日志配置
logging:
  level: "INFO"
  file: "logs/app.log"  # 相对于项目根目录MyRAG/
  max_bytes: 10485760  # 10MB
  backup_count: 5
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"

# WebSocket配置
websocket:
  heartbeat_interval: 30
  max_connections: 100

# LLM配置
llm:
  default_provider: "transformers"  # transformers, openai, azure
  default_model: "DeepSeek-OCR-3B"  # 默认模型名称(6GB显存使用更小的3B模型)
  local_models_dir: "Models"  # 本地模型根目录(包含LLM/和Embedding/), 相对于项目根目录
  transformers_quantization: "int4"  # 量化方式: int4(最省显存), int8, fp16
  transformers_max_memory: 5.5  # 最大显存使用(GB), RTX 3060 6GB建议5.5
  temperature: 0.7
  max_tokens: 512  # 降低到512以加快生成速度(CPU offload时很慢)

# Neo4j配置
neo4j:
  uri: "bolt://localhost:7687"  # 本地Neo4j连接
  username: "neo4j"
  password: "myrag123"  # 首次安装需要修改默认密码
  database: "neo4j"
  max_connection_lifetime: 3600
  max_connection_pool_size: 50
  connection_timeout: 30

# 知识图谱配置
knowledge_graph:
  enabled: true
  provider: "neo4j"  # neo4j
  
  # 实体提取配置
  entity_extraction:
    provider: "ollama"  # ollama
    ollama_model: "deepseek-v3.1:671b-cloud"  # 使用您的云端模型
    temperature: 0.1  # 低温度保证JSON输出稳定
    timeout: 60
    max_retries: 3
    batch_size: 5  # 并发提取数量
    min_text_length: 50  # 最小文本长度（过短不提取）
  
  # 图谱配置
  max_hops: 2  # 图遍历最大跳数
  min_entity_length: 2  # 最小实体长度
  enable_by_default: false  # 默认是否启用图谱构建
  
  # 实体类型定义
  entity_types:
    - Person  # 人物
    - Organization  # 组织
    - Location  # 地点
    - Product  # 产品
    - Concept  # 概念
    - Event  # 事件
    - Date  # 日期

# 混合检索配置
hybrid_retrieval:
  vector_weight: 0.6  # 向量检索权重
  graph_weight: 0.4   # 图谱检索权重
  enable_by_default: false  # 默认使用混合检索

# 数据库连接池配置
database:
  pool_size: 10
  max_overflow: 20
  pool_recycle: 3600
  echo: false
